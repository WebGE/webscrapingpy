{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source** : C0DING n°10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ressources** : <a href=\"https://webge.synology.me/dokuwiki/doku.php?id=python:accueilpython\" target=\"_blank\"><input type=\"button\" value=\"Wiki Python sur WebGE\"></a> <a href=\"http://fabpedigree.com/james/mathmen.htm\" target=\"_blank\"><input type=\"button\" value=\"Hundred Greatest Mathematicians of the Past\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présentation\n",
    "Le **Web scraping**, également appelé exploration de données Web ou récolte Web, est le processus de construction d'un agent qui peut extraire, analyser, télécharger et organiser automatiquement des informations utiles à partir du Web.\n",
    "\n",
    "#### Exploration Web et Web scraping\n",
    "L'exploration Web est essentiellement utilisée pour indexer les informations sur la page à l'aide de robots logiciels appelés **crawlers**. Le Web scraping est un moyen automatisé d'extraire les informations à l'aide de bots (aussi appelés **scrapers**).\n",
    "\n",
    "![](webscraping.jpg)\n",
    "\n",
    "#### Utilisation du Web scraping\n",
    "  * Sites Web de commerce en ligne\n",
    "  * Agrégateur de contenu\n",
    "  * Optimisation des moteurs de recherche\n",
    "  * Données pour les projets d'apprentissage automatique\n",
    "  * Données pour la recherche\n",
    " \n",
    "#### Composants d'un Web scraper\n",
    "![](webscraper.png)\n",
    "\n",
    "#### Fonctionnement d'un Web scraper\n",
    "  * **Etape 1** : téléchargement de contenu à partir de pages Web\n",
    "  * **Etape 2** : extraction, transformation et nettoyage des données\n",
    "  * **Etape 3** : stockage des données\n",
    "  * **Etape 4** : analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Problème\n",
    "Obtenir automatiquement la liste des **cent plus grands mathématiciens** de tous les temps à partir du site <a href=\"http://fabpedigree.com/james/mathmen.htm\" target=\"_blank\"><input type=\"button\" value=\"Hundred Greatest Mathematicians of the Past\"></a>.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La source d'information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le site <a href=\"http://fabpedigree.com/james/mathmen.htm\" target=\"_blank\"><input type=\"button\" value=\"Hundred Greatest Mathematicians of the Past\"></a> contient les informations que l'on souhaite récupérer.\n",
    "![](mathematiciens.png)\n",
    "\n",
    "Pour répondre au problème posé, le code ci-dessous :\n",
    "  * en téléchargeant la page contenant les information,\n",
    "  * en extrayant le nom des mathématiciens des balises html qui les contiennent,\n",
    "  * en supprimant le texte inutile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module ***requests*** permet d'envoyer des requêtes HTTP / 1.1 extrêmement facilement. ***BeautifulSoup*** est utilisé pour extraire des données de fichiers HTML et XML. ***contextlib*** fournit des utilitaires pour les tâches impliquant le mot-clé **with**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 'Web crawler' - Requête GET\n",
    "def simple_get(url):\n",
    "    ''' Tente d'obtenir le contenu situé à 'url'\n",
    "    en faisant une reqûete HTTP GET.\n",
    "    Si le type de réponse est du code HTML / XML,\n",
    "    renvoie le contenu textuel, sinon renvoi None'''\n",
    "    try:\n",
    "        # le mot clé with garantit que toutes les ressources réseau seront libérées\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "    except RequestException as e:\n",
    "        log_error(f'Erreur durant la requete {url}: {str(e)}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    ''' Renvoie True si la réponse\n",
    "    semble être du HTML, False sinon'''\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 and content_type is not None and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 'Extracteur' - Extraction, transformation et nettoyage de la  liste des mathématiciens\n",
    "def get_names(raw_html): \n",
    "    '''Télécharge la page où se trouve la liste des matématiciens et\n",
    "    renvoie une liste de chaines, une par matématicien'''\n",
    "    html = BeautifulSoup(raw_html, 'html.parser')\n",
    "    names = set()  # ensemble pour éliminer les éventuels doublons\n",
    "    for li in html.select('li'):\n",
    "        for name in li.text.split('\\n'):\n",
    "            if len(name) > 0:\n",
    "                names.add(name.strip())\n",
    "    return list(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test du module Web crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module **Web Crawler** effectue des **requêtes HTTP** pour télécharger le contenu demandé à partir d'une ou plusieurs pages Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web crawler\n",
    "# Requête GET vers un site qui n'existe pas => doit renvoyer None\n",
    "# raw_html = simple_get('https://realpython.com/blog/url_exemple') # renvoi None\n",
    "# Requête GET vers une page de test sur le site WEBGE => doit renvoyer le code de la page template.html\n",
    "raw_html = simple_get('http://p.mariano.free.fr/demos/serre1/template.html')\n",
    "# Affiche la réponse à la requête ou None\n",
    "print(raw_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test de l'action des modules Web crawler et Extracteur sur le site fabpedigree.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'**extracteur** traite le contenu HTML récupéré et extrait les données dans un format semi structuré. Il est également appelé module d'analyse et utilise différentes techniques d'analyse comme l'expression régulière, l'analyse HTML, l'analyse DOM ou l'intelligence artificielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de la liste \"non structurée\" des mathématiciens\n",
    "# Web crawler\n",
    "raw_html = simple_get('http://fabpedigree.com/james/mathmen.htm')\n",
    "# Extracteur\n",
    "html = BeautifulSoup(raw_html, 'html.parser')\n",
    "for i, li in enumerate(html.select('li')):\n",
    "    print(i, li.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Test de l'action des modules Web crawler, Extracteur et Transformation, Nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche la liste \"structurée\" des mathématiciens\n",
    "mathematiciens= [] # Liste des mathématiciens\n",
    "print('Obtention de la liste des mathématiciens')\n",
    "# Appel du Web crawler simple_get()\n",
    "raw_html = simple_get('http://fabpedigree.com/james/mathmen.htm')\n",
    "# Si le texte renvoyé est différent de None\n",
    "if raw_html != None:  # alors on récupère la liste des mathématiciens\n",
    "    mathematiciens = get_names(raw_html)  # appel de l'extracteur get_names\n",
    "for nom in mathematiciens:\n",
    "    print(nom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bitfee5dbd131124827be1a7a7c1e6211dd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
